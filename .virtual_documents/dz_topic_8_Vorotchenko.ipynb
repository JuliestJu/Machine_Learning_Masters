


!pip install category_encoders
!pip install gdown
import gdown
import warnings
import pandas as pd
import numpy as np
import category_encoders as ce
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import KBinsDiscretizer, StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_percentage_error
import category_encoders as ce
from scipy.stats import skew, kurtosis





url = 'https://drive.google.com/uc?id=19Zv1ldUlHPUihmSdRmNhcPwer-AGLYyZ'
output = 'mod_04_hw_train_data.csv'
gdown.download(url, output, quiet=False)
data_train = pd.read_csv(output)

url_val = 'https://drive.google.com/uc?id=1NGRGiGJAoHau8GJMLPuDciQiGv4q2Y9a'
output_val = 'mod_04_hw_valid_data.csv'
gdown.download(url_val, output_val, quiet=False)
data_val = pd.read_csv(output_val)


print(data_train.head())
print(data_val.head(7))





numerical_features = ['Experience']
categorical_features = ['Qualification', 'Role', 'Cert']


columns_to_drop = ['Date_Of_Birth', 'University', 'Phone_Number', 'Name']

df_train = data_train.drop(columns=columns_to_drop)
df_val = data_val.drop(columns=columns_to_drop)

print("Remaining columns after dropping:")
print(df_train.columns)

print("Remaining  df_val columns after dropping:")
print(df_val.columns)


# Заповнення числових стовпців середнім значенням
for column in numerical_features:
    df_train[column] = df_train[column].fillna(df_train[column].mode()[0])

# Заповнення категоріальних стовпців модою
for column in categorical_features:
    df_train[column] = df_train[column].fillna(df_train[column].mode()[0])

# Перевірка після заповнення
print(df_train.isnull().sum())
print(df_train.head(3))


Q1 = df_train['Experience'].quantile(0.25)
Q3 = df_train['Experience'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

train_data = df_train[(df_train['Experience'] >= lower_bound) & (df_train['Experience'] <= upper_bound)]

print("Розмірність після очищення:", df_train.shape)
print(df_train.head(3))





numerical_features = ['Experience']
categorical_features = ['Qualification', 'Role', 'Cert']

numerical_columns = numerical_features
categorical_columns = encoder.get_feature_names_out(categorical_features)
X_train_transformed = np.hstack((X_train_numerical, X_train_categorical))
X_train_df = pd.DataFrame(X_train_transformed, columns=numerical_columns + list(categorical_columns))


print(X_train_df.head(20))





model = KNeighborsRegressor(n_neighbors=4, weights='uniform', metric='manhattan')  # Вибір кількості сусідів
model.fit(X_train_transformed, y_train)

y_pred_train = model.predict(X_train_transformed)
mape = mean_absolute_percentage_error(y_train, y_pred_train)

print(f'Обчислена MAPE: {mape:.2%}')





X_valid = df_val.drop('Salary', axis=1)
y_valid = df_val['Salary']

X_valid_numerical = scaler.transform(X_valid[numerical_features])

X_valid_categorical = encoder.transform(X_valid[categorical_features]).toarray()

X_valid_transformed = np.hstack((X_valid_numerical, X_valid_categorical))

y_pred_valid = model.predict(X_valid_transformed)

mape_valid = mean_absolute_percentage_error(y_valid, y_pred_valid)
print(f'MAPE для валідаційного набору: {mape_valid:.2%}')






