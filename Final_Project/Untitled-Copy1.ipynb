{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409b7fb3-73aa-4b89-919d-a7a7872df215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install xgboost\n",
    "\n",
    "# Standard library imports\n",
    "import hashlib\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from category_encoders import TargetEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, PowerTransformer, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Local module imports\n",
    "from clean_data_helper import *\n",
    "from feature_summary import export_feature_summary\n",
    "from plot_histograms import *\n",
    "from preprocessing_helper import *\n",
    "from round_to_nearest import round_to_nearest_multiple\n",
    "from split_dataset_by_missing_and_type import *\n",
    "from numeric_imputer_helper import *\n",
    "from categorical_imputer_helper import *\n",
    "from transformer_helper import *\n",
    "from encoder_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f000026-b79e-4eb8-8d1d-2ca7d4b188e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 231)\n",
      "(2500, 230)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('final_proj_data.csv')\n",
    "test_data = pd.read_csv('final_proj_test.csv')\n",
    "\n",
    "print(data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2df0d8-bb44-4fe2-bcdf-3f7b6b158471",
   "metadata": {},
   "source": [
    "### Rough Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a640d758-b123-4e1b-bf0d-419f81829bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset shape after column removal: (10000, 67)\n",
      "New dataset shape after column removal: (2500, 66)\n",
      "(10000, 66)\n",
      "(2500, 66)\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = remove_columns_with_missing_values(data, 0.18)\n",
    "cleaned_test_data = remove_columns_with_missing_values(test_data, 0.18)\n",
    "\n",
    "y = cleaned_data['y']\n",
    "cleaned_data = cleaned_data.drop(columns=['y'])\n",
    "\n",
    "print(cleaned_data.shape)\n",
    "print(cleaned_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dbe0e8f-1a11-4b25-98b4-0b2123bc9873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_df.shape:  (10000, 38)\n",
      "categorical_df.shape:  (10000, 28)\n",
      "numeric_test_df.shape:  (2500, 38)\n",
      "categorical_test_df.shape:  (2500, 28)\n"
     ]
    }
   ],
   "source": [
    "numeric_df, categorical_df = split_dataset(cleaned_data)\n",
    "print('numeric_df.shape: ', numeric_df.shape)\n",
    "print('categorical_df.shape: ', categorical_df.shape)\n",
    "\n",
    "numeric_test_df, categorical_test_df = split_dataset(cleaned_test_data)\n",
    "print('numeric_test_df.shape: ', numeric_test_df.shape)\n",
    "print('categorical_test_df.shape: ', categorical_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5576789-8b59-4217-a2a2-73a7e2fd2f24",
   "metadata": {},
   "source": [
    "### Numerical Features Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd37324-bdc7-49e0-aaa3-377fff4f1af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 38)\n",
      "(2500, 38)\n"
     ]
    }
   ],
   "source": [
    "feature_categories = categorize_features(numeric_df)\n",
    "imputed_numeric_df = impute_data(numeric_df, feature_categories)\n",
    "\n",
    "imputed_test_numeric_df = impute_data(numeric_test_df, feature_categories)\n",
    "\n",
    "print(imputed_numeric_df.shape)\n",
    "print(imputed_test_numeric_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90202c1-7664-4163-aee9-fb3df5dabe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame before removing features:\n",
      "(10000, 38)\n",
      "\n",
      "Features with more than 10% outliers and their outlier percentages:\n",
      "        Outlier Count  Outlier Percentage\n",
      "Var113           1013               10.13\n",
      "Var132           1632               16.32\n",
      "\n",
      "DataFrame after removing features with more than 10% outliers:\n",
      "(10000, 36)\n",
      "DataFrame before removing features:\n",
      "(2500, 38)\n",
      "\n",
      "Features with more than 10% outliers and their outlier percentages:\n",
      "        Outlier Count  Outlier Percentage\n",
      "Var113            252               10.08\n",
      "Var132            388               15.52\n",
      "\n",
      "DataFrame after removing features with more than 10% outliers:\n",
      "(2500, 36)\n"
     ]
    }
   ],
   "source": [
    "outliners_cleaned_df = remove_outlier_features(imputed_numeric_df, outlier_percentage_threshold=10, iqr_threshold=3)\n",
    "outliners_test_cleaned_df = remove_outlier_features(imputed_test_numeric_df, outlier_percentage_threshold=10, iqr_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c80acd2-5bdb-4c8f-b9f3-cd2c0b47a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categorize_numeric_features_by_skewness(outliners_cleaned_df, skew_threshold=0.5, unique_value_threshold=10)\n",
    "transformed_numeric_df, transformers = transform_numeric_features(outliners_cleaned_df, categories)\n",
    "transformed_test_numeric_df = transform_numeric_features_test(outliners_test_cleaned_df, transformers, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6adda0-5796-4453-9bd6-e644f7272441",
   "metadata": {},
   "source": [
    "### Categorical Features Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f7b0a05-83a2-459d-b811-ad316896bf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Var192      Var193 Var195 Var196 Var197   Var198         Var199 Var202  \\\n",
      "0  KXMrEyXXnK  g62hiBSaKg   taul   1K8T   IvdZ  fhk21Ss        Pkku4gO   4MV4   \n",
      "1  8Knvyx875g     2Knk1KF   taul   1K8T   lK27  eQgnKxT  Hz673939hbJdw   sbhw   \n",
      "\n",
      "  Var203 Var204  ... Var217 Var218   Var219   Var220 Var221   Var222  \\\n",
      "0   9_Y1   SkZj  ...   G8WR   cJvF  AU8_WTd  4UxGlow   zCkv  catzS2D   \n",
      "1   9_Y1   MBhA  ...   5smi   UYBR  AU8pNoi  GpvRJ5l   oslk  i06ocsg   \n",
      "\n",
      "       Var223 Var226 Var227         Var228  \n",
      "0  jySVZNlOJy   Aoh3   ZI9m  ib5G6X1eUxUn6  \n",
      "1  LM8l689qOp   WqMG   RAYp        55YFVY9  \n",
      "\n",
      "[2 rows x 28 columns]\n",
      "       Var192               Var193 Var195 Var196 Var197   Var198      Var199  \\\n",
      "0  75lTmBtFkL  rEUOq2QD1qfkRr6qpua   taul   1K8T   F9g8  fhk21Ss  GVWDufEPyV   \n",
      "1  1YVgUHXZeb                 RO12   taul   1K8T   0Xwj  Ml6kiFp  S85OeCBjSz   \n",
      "\n",
      "  Var202 Var203 Var204  ... Var217 Var218 Var219   Var220 Var221   Var222  \\\n",
      "0   GHne   9_Y1   c2JP  ...   6ITF   cJvF   FzaX  4UxGlow   zCkv  catzS2D   \n",
      "1   14hG   HLqf   8BBI  ...   RRN_   UYBR   FzaX  k5O88FJ   oslk  QkgQQMs   \n",
      "\n",
      "       Var223 Var226 Var227         Var228  \n",
      "0  LM8l689qOp   rgKb   ZI9m  ib5G6X1eUxUn6  \n",
      "1  LM8l689qOp   453m   RAYp  F2FyR07IdsN7I  \n",
      "\n",
      "[2 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "categories = categorize_categorical_features(categorical_df, low_threshold=15, medium_threshold=100)\n",
    "imputed_categorical_df, imputers = impute_categorical_data(categorical_df, categories)\n",
    "imputed_test_categorical_df = impute_categorical_data_test(categorical_test_df, categories, imputers)\n",
    "print(imputed_categorical_df.head(2))\n",
    "print(imputed_test_categorical_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f856a22-978d-4749-bd54-220ecf9fb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_categories = categorize_categorical_features_for_encoding(imputed_categorical_df, low_cardinality_threshold=10, high_cardinality_threshold=100)\n",
    "encoded_categorical_df, encoders = encode_categorical_features(imputed_categorical_df, encoding_categories, target=y)\n",
    "encoded_test_categorical_df = encode_categorical_features_test(imputed_test_categorical_df, encoders, encoding_categories)\n",
    "encoded_test_categorical_df = encoded_test_categorical_df.reindex(columns=encoded_categorical_df.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef2c2b-d9cb-4c07-ab9a-7c0eb7ee38c6",
   "metadata": {},
   "source": [
    "### Model try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb87449e-b095-40e3-a1b6-51a9dabb4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([transformed_numeric_df, encoded_categorical_df], axis=1)\n",
    "X_test = pd.concat([transformed_test_numeric_df, encoded_test_categorical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaa75a18-c1f4-43da-a38c-cdb053997d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Results:\n",
      "Accuracy: 0.976\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       870\n",
      "           1       0.88      0.94      0.91       130\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.94      0.96      0.95      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "Fold Results:\n",
      "Accuracy: 0.971\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       870\n",
      "           1       0.89      0.88      0.89       130\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.94      0.93      0.94      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Fold Results:\n",
      "Accuracy: 0.975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       870\n",
      "           1       0.96      0.85      0.90       130\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.97      0.92      0.94      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Fold Results:\n",
      "Accuracy: 0.976\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       870\n",
      "           1       0.90      0.92      0.91       130\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.94      0.95      0.95      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "Fold Results:\n",
      "Accuracy: 0.974\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       870\n",
      "           1       0.89      0.92      0.90       130\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.94      0.95      0.94      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Fold Results:\n",
      "Accuracy: 0.972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       869\n",
      "           1       0.89      0.89      0.89       131\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.94      0.94      0.94      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Fold Results:\n",
      "Accuracy: 0.976\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       869\n",
      "           1       0.90      0.92      0.91       131\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.94      0.95      0.95      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "Fold Results:\n",
      "Accuracy: 0.98\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       869\n",
      "           1       0.89      0.97      0.93       131\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.94      0.98      0.96      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "Fold Results:\n",
      "Accuracy: 0.969\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       869\n",
      "           1       0.88      0.89      0.88       131\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.93      0.93      0.93      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Fold Results:\n",
      "Accuracy: 0.975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       869\n",
      "           1       0.91      0.89      0.90       131\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.95      0.94      0.94      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "\n",
      "F1 Scores for each fold: [0.9482954741305022, 0.935686897203267, 0.9418570847142276, 0.9476330121491412, 0.9432690964949029, 0.938509649592846, 0.9479668028201993, 0.9577099068772149, 0.9321412075800459, 0.9445576700028164]\n",
      "Average F1 Score: 0.9437626801565162\n",
      "Accuracies for each fold: [0.976, 0.971, 0.975, 0.976, 0.974, 0.972, 0.976, 0.98, 0.969, 0.975]\n",
      "Average Accuracy: 0.9743999999999999\n"
     ]
    }
   ],
   "source": [
    "strat_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in strat_kfold.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(\"Fold Results:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(\"\\nF1 Scores for each fold:\", f1_scores)\n",
    "print(\"Average F1 Score:\", np.mean(f1_scores))\n",
    "print(\"Accuracies for each fold:\", accuracies)\n",
    "print(\"Average Accuracy:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b5b08-be99-4ffc-af00-3f2e4915c1eb",
   "metadata": {},
   "source": [
    "### Test Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2bf449b-918d-46a0-9edb-cbd56cfcc5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39555d60-6a06-4507-bb8e-c866bf19b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_test_pred is your predictions and X_test has an 'ID' column\n",
    "submission_df = pd.DataFrame({\n",
    "    'index': X_test.index,  # or replace 'ID' with the column name if using specific column\n",
    "    'y': y_test_pred\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b7e5a-33f0-44e6-b5e2-7240e3382096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
