{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409b7fb3-73aa-4b89-919d-a7a7872df215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "\n",
    "import hashlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from category_encoders import TargetEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, PowerTransformer, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from clean_data_helper import *\n",
    "from feature_summary import *\n",
    "from plot_histograms import *\n",
    "from preprocessing_helper import *\n",
    "from numeric_imputer_helper import *\n",
    "from categorical_imputer_helper import *\n",
    "from transformer_helper import *\n",
    "from encoder_helper import *\n",
    "from rounding_helper import *\n",
    "from corellation_based_reducer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f000026-b79e-4eb8-8d1d-2ca7d4b188e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 231)\n",
      "(2500, 230)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('final_proj_data.csv')\n",
    "test_data = pd.read_csv('final_proj_test.csv')\n",
    "\n",
    "print(data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2df0d8-bb44-4fe2-bcdf-3f7b6b158471",
   "metadata": {},
   "source": [
    "### Rough Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a640d758-b123-4e1b-bf0d-419f81829bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset shape after column removal: (10000, 67)\n",
      "New dataset shape after column removal: (2500, 66)\n",
      "(10000, 66)\n",
      "(2500, 66)\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = remove_columns_with_missing_values(data, 0.18)\n",
    "cleaned_test_data = remove_columns_with_missing_values(test_data, 0.18)\n",
    "\n",
    "y = cleaned_data['y']\n",
    "cleaned_data = cleaned_data.drop(columns=['y'])\n",
    "\n",
    "print(cleaned_data.shape)\n",
    "print(cleaned_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dbe0e8f-1a11-4b25-98b4-0b2123bc9873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_df.shape:  (10000, 38)\n",
      "categorical_df.shape:  (10000, 28)\n",
      "numeric_test_df.shape:  (2500, 38)\n",
      "categorical_test_df.shape:  (2500, 28)\n"
     ]
    }
   ],
   "source": [
    "numeric_df, categorical_df = split_dataset(cleaned_data)\n",
    "print('numeric_df.shape: ', numeric_df.shape)\n",
    "print('categorical_df.shape: ', categorical_df.shape)\n",
    "\n",
    "numeric_test_df, categorical_test_df = split_dataset(cleaned_test_data)\n",
    "print('numeric_test_df.shape: ', numeric_test_df.shape)\n",
    "print('categorical_test_df.shape: ', categorical_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5576789-8b59-4217-a2a2-73a7e2fd2f24",
   "metadata": {},
   "source": [
    "### Numerical Features Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd37324-bdc7-49e0-aaa3-377fff4f1af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 38)\n",
      "(2500, 38)\n"
     ]
    }
   ],
   "source": [
    "feature_categories = categorize_features(numeric_df)\n",
    "imputed_numeric_df = impute_data(numeric_df, feature_categories)\n",
    "\n",
    "imputed_test_numeric_df = impute_data(numeric_test_df, feature_categories)\n",
    "\n",
    "print(imputed_numeric_df.shape)\n",
    "print(imputed_test_numeric_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90202c1-7664-4163-aee9-fb3df5dabe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame before removing features:\n",
      "(12500, 38)\n",
      "\n",
      "Features with more than 6% outliers and their outlier percentages:\n",
      "        Outlier Count  Outlier Percentage\n",
      "Var35             948               7.584\n",
      "Var78             910               7.280\n",
      "Var113           1259              10.072\n",
      "Var132           2020              16.160\n",
      "\n",
      "DataFrame after removing features with more than 6% outliers:\n",
      "(12500, 34)\n"
     ]
    }
   ],
   "source": [
    "combined_df_outliners = pd.concat([imputed_numeric_df, imputed_test_numeric_df], axis=0)\n",
    "outliners_cleaned_combined_df = remove_outlier_features(combined_df_outliners, outlier_percentage_threshold=6, iqr_threshold=3)\n",
    "\n",
    "outliners_cleaned_df = outliners_cleaned_combined_df.iloc[:len(imputed_numeric_df), :].reset_index(drop=True)\n",
    "outliners_test_cleaned_df = outliners_cleaned_combined_df.iloc[len(imputed_numeric_df):, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6f63c2-a733-4b21-b60d-0460ef3eb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounding_features = find_rounding_features(outliners_cleaned_df)\n",
    "rounding_test_features = find_rounding_features(outliners_test_cleaned_df)\n",
    "\n",
    "numeric_rounded_df = round_detected_features(outliners_cleaned_df, rounding_features)\n",
    "numericTest_rounded_df = round_detected_features(outliners_test_cleaned_df, rounding_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4bd778-0338-417b-9092-56700ed26f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([numeric_rounded_df, numericTest_rounded_df], axis=0)\n",
    "reduced_combined_df, dropped_columns_combined = correlation_based_elimination(combined_df, threshold=0.9)\n",
    "\n",
    "reduced_train_df = reduced_combined_df.iloc[:len(numeric_rounded_df), :].reset_index(drop=True)\n",
    "reduced_test_df = reduced_combined_df.iloc[len(numeric_rounded_df):, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c80acd2-5bdb-4c8f-b9f3-cd2c0b47a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categorize_numeric_features_by_skewness_and_variance(reduced_train_df,\n",
    "                                                                  skew_threshold=7,\n",
    "                                                                  unique_value_threshold=7,\n",
    "                                                                  variance_threshold=0.01)\n",
    "transformed_numeric_df, transformers = transform_numeric_features(reduced_train_df, categories)\n",
    "transformed_test_numeric_df = transform_numeric_features_test(reduced_test_df, transformers, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6adda0-5796-4453-9bd6-e644f7272441",
   "metadata": {},
   "source": [
    "### Categorical Features Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f7b0a05-83a2-459d-b811-ad316896bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categorize_categorical_features(categorical_df, low_threshold=10, medium_threshold=100)\n",
    "imputed_categorical_df, imputers = impute_categorical_data(categorical_df, categories)\n",
    "imputed_test_categorical_df = impute_categorical_data_test(categorical_test_df, categories, imputers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f856a22-978d-4749-bd54-220ecf9fb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_categories = categorize_categorical_features_for_encoding(imputed_categorical_df, low_cardinality_threshold=10,\n",
    "                                                                   high_cardinality_threshold=100)\n",
    "encoded_categorical_df, encoders = encode_categorical_features(imputed_categorical_df, encoding_categories, target=y)\n",
    "encoded_test_categorical_df = encode_categorical_features_test(imputed_test_categorical_df, encoders, encoding_categories)\n",
    "encoded_test_categorical_df = encoded_test_categorical_df.reindex(columns=encoded_categorical_df.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef2c2b-d9cb-4c07-ab9a-7c0eb7ee38c6",
   "metadata": {},
   "source": [
    "### Model try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb87449e-b095-40e3-a1b6-51a9dabb4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([transformed_numeric_df, encoded_categorical_df], axis=1)\n",
    "X_test = pd.concat([transformed_test_numeric_df, encoded_test_categorical_df], axis=1)\n",
    "X_combined = pd.concat([X, X_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaa75a18-c1f4-43da-a38c-cdb053997d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Scores for each fold: [0.9523029025851826, 0.939322433844598, 0.9443780070639931, 0.9452751674032629, 0.9439867636413775, 0.940897180795524, 0.9496531540110019, 0.9492518882526579, 0.9412756239464956, 0.9441903243881585]\n",
      "Average F1 Score: 0.9450533445932251\n",
      "Accuracies for each fold: [0.978, 0.973, 0.976, 0.975, 0.974, 0.973, 0.977, 0.976, 0.973, 0.975]\n",
      "Average Accuracy: 0.975\n",
      "\n",
      "Selected Features Based on Importance Threshold: ['Var7', 'Var24', 'Var44', 'Var65', 'Var73', 'Var74', 'Var143', 'Var144', 'Var173', 'Var193', 'Var198', 'Var199', 'Var202', 'Var207', 'Var211', 'Var212', 'Var216', 'Var217', 'Var218', 'Var220', 'Var222', 'Var205_09_Q', 'Var205_sJzTlal', 'Var221_Al6ZaUT', 'Var221_oslk', 'Var221_zCkv', 'Var227_6fzt']\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'subsample': 1.0,\n",
    "    'reg_lambda': 1,\n",
    "    'reg_alpha': 0.01,\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.1,\n",
    "    'gamma': 0,\n",
    "    'colsample_bytree': 0.6\n",
    "}\n",
    "\n",
    "model = XGBClassifier(eval_metric='logloss', random_state=42, **best_params)\n",
    "\n",
    "strat_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "feature_importance_dict = {}\n",
    "\n",
    "for train_index, val_index in strat_kfold.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    importances = model.feature_importances_\n",
    "    for i, feature in enumerate(X.columns):\n",
    "        if feature not in feature_importance_dict:\n",
    "            feature_importance_dict[feature] = []\n",
    "        feature_importance_dict[feature].append(importances[i])\n",
    "    \n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(\"\\nF1 Scores for each fold:\", f1_scores)\n",
    "print(\"Average F1 Score:\", np.mean(f1_scores))\n",
    "print(\"Accuracies for each fold:\", accuracies)\n",
    "print(\"Average Accuracy:\", np.mean(accuracies))\n",
    "\n",
    "avg_importances = {feature: np.mean(importances) for feature, importances in feature_importance_dict.items()}\n",
    "importance_threshold = 0.008\n",
    "selected_features = [feature for feature, importance in avg_importances.items() if importance >= importance_threshold]\n",
    "\n",
    "print(\"\\nSelected Features Based on Importance Threshold:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2bf449b-918d-46a0-9edb-cbd56cfcc5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "model.fit(X_train_selected, y)\n",
    "y_test_pred = model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c5194c1-0466-4ce3-8d37-ac6e7f71c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = pd.concat([X[selected_features], X_test[selected_features]], axis=0)\n",
    "y_combined = np.concatenate([y, y_test_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08b5850c-d148-4648-8943-7972678276a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Scores for each fold: [0.9309160162814145, 0.9216709384662176, 0.9466622777340916, 0.911129016968433, 0.9530562978919649, 0.9230123285428224, 0.9329722773339053, 0.9300338783325969, 0.9478673268152598, 0.941405334458351]\n",
      "Average F1 Score: 0.9338725692825056\n",
      "Accuracies for each fold: [0.9704, 0.9672, 0.9776, 0.9616, 0.98, 0.9672, 0.9712, 0.9696, 0.9776, 0.9744]\n",
      "Average Accuracy: 0.9716799999999999\n"
     ]
    }
   ],
   "source": [
    "strat_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "model2 = XGBClassifier(eval_metric='logloss', random_state=42, **best_params)\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in strat_kfold.split(X_combined, y_combined):\n",
    "    X_train, X_val = X_combined.iloc[train_index], X_combined.iloc[val_index]\n",
    "    y_train, y_val = y_combined[train_index], y_combined[val_index]\n",
    "    \n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model2.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    y_val_pred = model2.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(\"\\nF1 Scores for each fold:\", f1_scores)\n",
    "print(\"Average F1 Score:\", np.mean(f1_scores))\n",
    "print(\"Accuracies for each fold:\", accuracies)\n",
    "print(\"Average Accuracy:\", np.mean(accuracies))\n",
    "\n",
    "y_common_pred = model.predict(X_test[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8110ff-26bf-40e3-987f-6af448c7e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'index': X_test.index,\n",
    "    'y': y_common_pred\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
