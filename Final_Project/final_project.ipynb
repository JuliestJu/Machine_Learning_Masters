{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aec290c0-c953-49f0-8d57-d643137b2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from feature_summary import export_feature_summary\n",
    "from round_to_nearest import round_to_nearest_multiple\n",
    "from split_dataset_by_missing_and_type import split_dataset_by_missing_and_type\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f52f9b-e6d3-4358-bfda-c25dee74c5a9",
   "metadata": {},
   "source": [
    "### Пояснення до кожного файлу:\n",
    "\n",
    "**final_proj_data.csv**: Це навчальний набір даних, який використовується для побудови та навчання вашої моделі машинного навчання.\n",
    "**final_proj_test.csv**: Це тестовий набір даних, на якому ви генеруватимете прогнози для подальшої оцінки.\n",
    "\n",
    "**final_proj_sample_submission.csv**: Це приклад правильного формату та структури для подання ваших прогнозів на Kaggle.\n",
    "\n",
    "**final_project.ipynb**: Це Jupyter Notebook, де ви пишете код, тренуєте свою модель і генеруєте прогнози для змагання."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1abe2ed-73c5-43c9-83ba-7b49b4b0d8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_proj_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb3adc0-34a9-49b7-9d60-72abe84f2b9f",
   "metadata": {},
   "source": [
    "### Removing Missing Rows and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae704a41-ab37-4d91-8224-ea5cc14996ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 231)\n",
      "Columns removed: ['Var1', 'Var2', 'Var3', 'Var4', 'Var5', 'Var8', 'Var9', 'Var10', 'Var11', 'Var12', 'Var14', 'Var15', 'Var16', 'Var17', 'Var18', 'Var19', 'Var20', 'Var23', 'Var26', 'Var27', 'Var29', 'Var30', 'Var31', 'Var32', 'Var33', 'Var34', 'Var36', 'Var37', 'Var39', 'Var40', 'Var41', 'Var42', 'Var43', 'Var45', 'Var46', 'Var47', 'Var48', 'Var49', 'Var50', 'Var51', 'Var52', 'Var53', 'Var54', 'Var55', 'Var56', 'Var58', 'Var59', 'Var60', 'Var61', 'Var62', 'Var63', 'Var64', 'Var66', 'Var67', 'Var68', 'Var69', 'Var70', 'Var71', 'Var72', 'Var75', 'Var77', 'Var79', 'Var80', 'Var82', 'Var84', 'Var86', 'Var87', 'Var88', 'Var89', 'Var90', 'Var91', 'Var92', 'Var93', 'Var94', 'Var95', 'Var96', 'Var97', 'Var98', 'Var99', 'Var100', 'Var101', 'Var102', 'Var103', 'Var104', 'Var105', 'Var106', 'Var107', 'Var108', 'Var110', 'Var111', 'Var114', 'Var115', 'Var116', 'Var117', 'Var118', 'Var120', 'Var121', 'Var122', 'Var124', 'Var127', 'Var128', 'Var129', 'Var130', 'Var131', 'Var135', 'Var136', 'Var137', 'Var138', 'Var139', 'Var141', 'Var142', 'Var145', 'Var146', 'Var147', 'Var148', 'Var150', 'Var151', 'Var152', 'Var154', 'Var155', 'Var156', 'Var157', 'Var158', 'Var159', 'Var161', 'Var162', 'Var164', 'Var165', 'Var166', 'Var167', 'Var168', 'Var169', 'Var170', 'Var171', 'Var172', 'Var174', 'Var175', 'Var176', 'Var177', 'Var178', 'Var179', 'Var180', 'Var182', 'Var183', 'Var184', 'Var185', 'Var186', 'Var187', 'Var188', 'Var189', 'Var190', 'Var191', 'Var194', 'Var200', 'Var201', 'Var209', 'Var213', 'Var214', 'Var215', 'Var224', 'Var225', 'Var229', 'Var230']\n",
      "New dataset shape after column removal: (10000, 68)\n",
      "New dataset shape after removing rows with more than 30% missing columns: (9080, 68)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "column_threshold = 0.30\n",
    "\n",
    "missing_percent = data.isnull().mean()\n",
    "columns_to_drop = missing_percent[missing_percent > column_threshold].index\n",
    "cleaned_data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Columns removed: {list(columns_to_drop)}\")\n",
    "print(f\"New dataset shape after column removal: {cleaned_data.shape}\")\n",
    "\n",
    "row_threshold = int((1 - 0.30) * cleaned_data.shape[1])\n",
    "cleaned_data = cleaned_data.dropna(thresh=row_threshold)\n",
    "print(f\"New dataset shape after removing rows with more than 30% missing columns: {cleaned_data.shape}\")\n",
    "\n",
    "cleaned_data.to_csv('fully_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afa0d03-0b59-4ff8-af61-fa0fb1b1f15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature summary exported to feature_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Separate numeric and categorical feature names\n",
    "numeric_features = cleaned_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = cleaned_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "export_feature_summary(cleaned_data, 'feature_summary.csv', unique_threshold = 40)\n",
    "summary_df = pd.read_csv('feature_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4f5ad-7421-4e44-98c7-a7dcfd78321e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941ac169-ebad-4aec-a2fd-96cbba9d6a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Files saved successfully.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MISSING VALUES\n",
    "features_with_missing_values_count = summary_df[summary_df['Missing Value Count'] > 0].shape[0]\n",
    "print(features_with_missing_values_count)\n",
    "split_dataset_by_missing_and_type(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15cebead-5755-4194-a631-235db51f6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables with no missing values\n",
    "categorical_variables_no_missing = [\n",
    "    'Var196', 'Var207', 'Var226', 'Var211', 'Var198', 'Var199', \n",
    "    'Var202', 'Var204', 'Var212', 'Var216', 'Var220', 'Var222', \n",
    "    'Var227', 'Var193', 'Var228', 'Var195', 'Var210', 'Var221'\n",
    "]\n",
    "\n",
    "# Numerical variables with no missing values\n",
    "numerical_variables_no_missing = [\n",
    "    'y', 'Var181', 'Var173', 'Var35', 'Var143', 'Var132', 'Var78', 'Var44',\n",
    "    'Var163', 'Var160', 'Var153', 'Var134', 'Var133', 'Var123', 'Var22', 'Var85',\n",
    "    'Var83', 'Var76', 'Var73', 'Var57', 'Var38', 'Var28', 'Var25', 'Var113', 'Var112'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd7b131-8d71-4bb1-837d-36d41d709dfc",
   "metadata": {},
   "source": [
    "### Numerical imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70e37c2a-bd5c-4337-9003-f56325298c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical continuous variables with missing values <= 100\n",
    "numerical_continuous_missing_leq_100 = ['Var6', 'Var13', 'Var21', 'Var74', 'Var81', 'Var119', 'Var125', 'Var140']\n",
    "# Perform median imputation for the specified variables\n",
    "for col in numerical_continuous_missing_leq_100:\n",
    "    if col in cleaned_data.columns:\n",
    "        median_value = cleaned_data[col].median()\n",
    "        cleaned_data[col] = cleaned_data[col].fillna(median_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58dc4579-e2e6-4ea5-9c57-91cbe6fd4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical continuous variables with missing values > 100 and <= 1000\n",
    "numerical_continuous_missing_between_100_and_1000 = ['Var24', 'Var109', 'Var149']\n",
    "# Numerical continuous variables with missing values > 1000\n",
    "numerical_continuous_missing_gt_1000 = ['Var126']\n",
    "# Numerical ordinal variables with a common divisor of 7\n",
    "numerical_ordinal_divisor_7_group = ['Var7']\n",
    "# Numerical ordinal variables with a common divisor of 9\n",
    "numerical_ordinal_divisor_9_group = ['Var144', 'Var65']\n",
    "\n",
    "# Create a SimpleImputer object with the median strategy\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Apply the imputation on the selected columns\n",
    "cleaned_data[numerical_continuous_missing_gt_1000] = median_imputer.fit_transform(cleaned_data[numerical_continuous_missing_gt_1000])\n",
    "cleaned_data[numerical_continuous_missing_between_100_and_1000] = median_imputer.fit_transform(cleaned_data[numerical_continuous_missing_between_100_and_1000])\n",
    "cleaned_data[numerical_ordinal_divisor_7_group] = median_imputer.fit_transform(cleaned_data[numerical_ordinal_divisor_7_group])\n",
    "cleaned_data[numerical_ordinal_divisor_9_group] = median_imputer.fit_transform(cleaned_data[numerical_ordinal_divisor_9_group])\n",
    "\n",
    "# Apply rounding to nearest multiple of 7 for Var7\n",
    "cleaned_data[numerical_ordinal_divisor_7_group] = cleaned_data[numerical_ordinal_divisor_7_group].apply(lambda x: round_to_nearest_multiple(x, 7))\n",
    "\n",
    "# Apply rounding to nearest multiple of 9 for Var144 and Var65\n",
    "for var in numerical_ordinal_divisor_9_group:\n",
    "    cleaned_data[var] = cleaned_data[var].apply(lambda x: round_to_nearest_multiple(x, 9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425ad60-f52d-4571-815a-36eaffd553ac",
   "metadata": {},
   "source": [
    "### Categorical Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4355fa14-de28-45e8-8da1-071d8c4b362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORICAL\n",
    "# Categorical continuous variables\n",
    "categorical_continuous_variables = ['Var192', 'Var197', 'Var217']\n",
    "\n",
    "# Create SimpleImputer object with the most frequent strategy\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "cleaned_data[categorical_continuous_variables] = mode_imputer.fit_transform(cleaned_data[categorical_continuous_variables])\n",
    "\n",
    "# Categorical variables with few unique values and up to 345 missing\n",
    "categorical_variables_few_unique_missing_leq_345 = ['Var203', 'Var205', 'Var218', 'Var208']\n",
    "cleaned_data[categorical_variables_few_unique_missing_leq_345] = mode_imputer.fit_transform(cleaned_data[categorical_variables_few_unique_missing_leq_345])\n",
    "\n",
    "# Categorical variables with many unique values and little missing\n",
    "categorical_variables_many_unique_missing_low = ['Var206']\n",
    "# Apply the imputation\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "cleaned_data[categorical_variables_many_unique_missing_low] = constant_imputer.fit_transform(cleaned_data[categorical_variables_many_unique_missing_low])\n",
    "\n",
    "# Categorical variables with many unique values and many missing\n",
    "categorical_variables_many_unique_missing_high = ['Var219']\n",
    "# Apply the KNN imputation on categorical variables with many unique values\n",
    "cleaned_data[categorical_variables_many_unique_missing_high] = constant_imputer.fit_transform(cleaned_data[categorical_variables_many_unique_missing_high])\n",
    "\n",
    "# Categorical variables with few unique values and many missing\n",
    "categorical_variables_few_unique_missing_high = ['Var223']\n",
    "# Apply most frequent imputation\n",
    "cleaned_data[categorical_variables_few_unique_missing_high] = mode_imputer.fit_transform(cleaned_data[categorical_variables_few_unique_missing_high])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228235b5-d676-45ce-aade-b1ad6724bab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
