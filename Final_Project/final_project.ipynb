{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409b7fb3-73aa-4b89-919d-a7a7872df215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install xgboost\n",
    "\n",
    "# Standard library imports\n",
    "import hashlib\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from category_encoders import TargetEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, PowerTransformer, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Local module imports\n",
    "from clean_data_helper import *\n",
    "from feature_summary import *\n",
    "from plot_histograms import *\n",
    "from preprocessing_helper import *\n",
    "from numeric_imputer_helper import *\n",
    "from categorical_imputer_helper import *\n",
    "from transformer_helper import *\n",
    "from encoder_helper import *\n",
    "from rounding_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f000026-b79e-4eb8-8d1d-2ca7d4b188e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 231)\n",
      "(2500, 230)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('final_proj_data.csv')\n",
    "test_data = pd.read_csv('final_proj_test.csv')\n",
    "\n",
    "print(data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2df0d8-bb44-4fe2-bcdf-3f7b6b158471",
   "metadata": {},
   "source": [
    "### Rough Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a640d758-b123-4e1b-bf0d-419f81829bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset shape after column removal: (10000, 67)\n",
      "New dataset shape after column removal: (2500, 66)\n",
      "(10000, 66)\n",
      "(2500, 66)\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = remove_columns_with_missing_values(data, 0.18)\n",
    "cleaned_test_data = remove_columns_with_missing_values(test_data, 0.18)\n",
    "\n",
    "y = cleaned_data['y']\n",
    "cleaned_data = cleaned_data.drop(columns=['y'])\n",
    "\n",
    "print(cleaned_data.shape)\n",
    "print(cleaned_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dbe0e8f-1a11-4b25-98b4-0b2123bc9873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_df.shape:  (10000, 38)\n",
      "categorical_df.shape:  (10000, 28)\n",
      "numeric_test_df.shape:  (2500, 38)\n",
      "categorical_test_df.shape:  (2500, 28)\n"
     ]
    }
   ],
   "source": [
    "numeric_df, categorical_df = split_dataset(cleaned_data)\n",
    "print('numeric_df.shape: ', numeric_df.shape)\n",
    "print('categorical_df.shape: ', categorical_df.shape)\n",
    "\n",
    "numeric_test_df, categorical_test_df = split_dataset(cleaned_test_data)\n",
    "print('numeric_test_df.shape: ', numeric_test_df.shape)\n",
    "print('categorical_test_df.shape: ', categorical_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5576789-8b59-4217-a2a2-73a7e2fd2f24",
   "metadata": {},
   "source": [
    "### Numerical Features Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd37324-bdc7-49e0-aaa3-377fff4f1af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 38)\n",
      "(2500, 38)\n"
     ]
    }
   ],
   "source": [
    "feature_categories = categorize_features(numeric_df)\n",
    "imputed_numeric_df = impute_data(numeric_df, feature_categories)\n",
    "\n",
    "imputed_test_numeric_df = impute_data(numeric_test_df, feature_categories)\n",
    "\n",
    "print(imputed_numeric_df.shape)\n",
    "print(imputed_test_numeric_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90202c1-7664-4163-aee9-fb3df5dabe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame before removing features:\n",
      "(10000, 38)\n",
      "\n",
      "Features with more than 10% outliers and their outlier percentages:\n",
      "        Outlier Count  Outlier Percentage\n",
      "Var113           1013               10.13\n",
      "Var132           1632               16.32\n",
      "\n",
      "DataFrame after removing features with more than 10% outliers:\n",
      "(10000, 36)\n",
      "DataFrame before removing features:\n",
      "(2500, 38)\n",
      "\n",
      "Features with more than 10% outliers and their outlier percentages:\n",
      "        Outlier Count  Outlier Percentage\n",
      "Var113            252               10.08\n",
      "Var132            388               15.52\n",
      "\n",
      "DataFrame after removing features with more than 10% outliers:\n",
      "(2500, 36)\n"
     ]
    }
   ],
   "source": [
    "outliners_cleaned_df = remove_outlier_features(imputed_numeric_df, outlier_percentage_threshold=10, iqr_threshold=3)\n",
    "outliners_test_cleaned_df = remove_outlier_features(imputed_test_numeric_df, outlier_percentage_threshold=10, iqr_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6f63c2-a733-4b21-b60d-0460ef3eb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounding_features = find_rounding_features(outliners_cleaned_df)\n",
    "rounding_test_features = find_rounding_features(outliners_test_cleaned_df)\n",
    "\n",
    "numeric_rounded_df = round_detected_features(outliners_cleaned_df, rounding_features)\n",
    "numericTest_rounded_df = round_detected_features(outliners_test_cleaned_df, rounding_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c80acd2-5bdb-4c8f-b9f3-cd2c0b47a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categorize_numeric_features_by_skewness_and_variance(numeric_rounded_df,\n",
    "                                                                  skew_threshold=7,\n",
    "                                                                  unique_value_threshold=7,\n",
    "                                                                  variance_threshold=0.01)\n",
    "transformed_numeric_df, transformers = transform_numeric_features(numeric_rounded_df, categories)\n",
    "transformed_test_numeric_df = transform_numeric_features_test(numericTest_rounded_df, transformers, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6adda0-5796-4453-9bd6-e644f7272441",
   "metadata": {},
   "source": [
    "### Categorical Features Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7b0a05-83a2-459d-b811-ad316896bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categorize_categorical_features(categorical_df, low_threshold=10, medium_threshold=100)\n",
    "imputed_categorical_df, imputers = impute_categorical_data(categorical_df, categories)\n",
    "imputed_test_categorical_df = impute_categorical_data_test(categorical_test_df, categories, imputers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f856a22-978d-4749-bd54-220ecf9fb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_categories = categorize_categorical_features_for_encoding(imputed_categorical_df, low_cardinality_threshold=10,\n",
    "                                                                   high_cardinality_threshold=100)\n",
    "encoded_categorical_df, encoders = encode_categorical_features(imputed_categorical_df, encoding_categories, target=y)\n",
    "encoded_test_categorical_df = encode_categorical_features_test(imputed_test_categorical_df, encoders, encoding_categories)\n",
    "encoded_test_categorical_df = encoded_test_categorical_df.reindex(columns=encoded_categorical_df.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef2c2b-d9cb-4c07-ab9a-7c0eb7ee38c6",
   "metadata": {},
   "source": [
    "### Model try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb87449e-b095-40e3-a1b6-51a9dabb4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([transformed_numeric_df, encoded_categorical_df], axis=1)\n",
    "X_test = pd.concat([transformed_test_numeric_df, encoded_test_categorical_df], axis=1)\n",
    "X_combined = pd.concat([X, X_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaa75a18-c1f4-43da-a38c-cdb053997d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Scores for each fold: [0.950605511995344, 0.941764621559633, 0.9397428409859925, 0.9432690964949029, 0.931917211328976, 0.940897180795524, 0.9377199933854338, 0.9450228789403794, 0.9321412075800459, 0.9465997383387179]\n",
      "Average F1 Score: 0.9409680281404948\n",
      "Accuracies for each fold: [0.977, 0.974, 0.974, 0.974, 0.968, 0.973, 0.971, 0.974, 0.969, 0.976]\n",
      "Average Accuracy: 0.9730000000000001\n"
     ]
    }
   ],
   "source": [
    "strat_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in strat_kfold.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(\"\\nF1 Scores for each fold:\", f1_scores)\n",
    "print(\"Average F1 Score:\", np.mean(f1_scores))\n",
    "print(\"Accuracies for each fold:\", accuracies)\n",
    "print(\"Average Accuracy:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2bf449b-918d-46a0-9edb-cbd56cfcc5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39555d60-6a06-4507-bb8e-c866bf19b37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb8b7e5a-33f0-44e6-b5e2-7240e3382096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_combined shape: (12500, 91)\n",
      "y_combined shape: (12500,)\n"
     ]
    }
   ],
   "source": [
    "y_combined = np.concatenate([y, y_test_pred])\n",
    "\n",
    "print(\"X_combined shape:\", X_combined.shape)\n",
    "print(\"y_combined shape:\", y_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08b5850c-d148-4648-8943-7972678276a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Scores for each fold: [0.9943017691867029, 0.9943017691867029, 0.9905574717592865, 0.9943667557470357, 0.9925103058191928, 0.9981222519156785, 0.9981114943518573, 1.0, 0.9981222519156785, 0.9943667557470357]\n",
      "Average F1 Score: 0.9954760825629171\n",
      "Accuracies for each fold: [0.9976, 0.9976, 0.996, 0.9976, 0.9968, 0.9992, 0.9992, 1.0, 0.9992, 0.9976]\n",
      "Average Accuracy: 0.9980800000000001\n"
     ]
    }
   ],
   "source": [
    "strat_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "model2 = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in strat_kfold.split(X_combined, y_combined):\n",
    "    X_train, X_val = X_combined.iloc[train_index], X_combined.iloc[val_index]\n",
    "    y_train, y_val = y_combined[train_index], y_combined[val_index]\n",
    "    \n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model2.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(\"\\nF1 Scores for each fold:\", f1_scores)\n",
    "print(\"Average F1 Score:\", np.mean(f1_scores))\n",
    "print(\"Accuracies for each fold:\", accuracies)\n",
    "print(\"Average Accuracy:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3362bd4c-d682-4dec-8b5e-9becb5d3c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_common_pred = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8110ff-26bf-40e3-987f-6af448c7e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_test_pred is your predictions and X_test has an 'ID' column\n",
    "submission_df = pd.DataFrame({\n",
    "    'index': X_test.index,  # or replace 'ID' with the column name if using specific column\n",
    "    'y': y_common_pred\n",
    "})\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516c555-319d-455a-8721-3b978feed834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
