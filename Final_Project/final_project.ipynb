{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aec290c0-c953-49f0-8d57-d643137b2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_summary import export_feature_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f52f9b-e6d3-4358-bfda-c25dee74c5a9",
   "metadata": {},
   "source": [
    "### Пояснення до кожного файлу:\n",
    "\n",
    "**final_proj_data.csv**: Це навчальний набір даних, який використовується для побудови та навчання вашої моделі машинного навчання.\n",
    "**final_proj_test.csv**: Це тестовий набір даних, на якому ви генеруватимете прогнози для подальшої оцінки.\n",
    "\n",
    "**final_proj_sample_submission.csv**: Це приклад правильного формату та структури для подання ваших прогнозів на Kaggle.\n",
    "\n",
    "**final_project.ipynb**: Це Jupyter Notebook, де ви пишете код, тренуєте свою модель і генеруєте прогнози для змагання."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1abe2ed-73c5-43c9-83ba-7b49b4b0d8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_proj_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb3adc0-34a9-49b7-9d60-72abe84f2b9f",
   "metadata": {},
   "source": [
    "### Removing Missing Rows and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae704a41-ab37-4d91-8224-ea5cc14996ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 231)\n",
      "Columns removed: ['Var1', 'Var2', 'Var3', 'Var4', 'Var5', 'Var8', 'Var9', 'Var10', 'Var11', 'Var12', 'Var14', 'Var15', 'Var16', 'Var17', 'Var18', 'Var19', 'Var20', 'Var23', 'Var26', 'Var27', 'Var29', 'Var30', 'Var31', 'Var32', 'Var33', 'Var34', 'Var36', 'Var37', 'Var39', 'Var40', 'Var41', 'Var42', 'Var43', 'Var45', 'Var46', 'Var47', 'Var48', 'Var49', 'Var50', 'Var51', 'Var52', 'Var53', 'Var54', 'Var55', 'Var56', 'Var58', 'Var59', 'Var60', 'Var61', 'Var62', 'Var63', 'Var64', 'Var66', 'Var67', 'Var68', 'Var69', 'Var70', 'Var71', 'Var72', 'Var75', 'Var77', 'Var79', 'Var80', 'Var82', 'Var84', 'Var86', 'Var87', 'Var88', 'Var89', 'Var90', 'Var91', 'Var92', 'Var93', 'Var94', 'Var95', 'Var96', 'Var97', 'Var98', 'Var99', 'Var100', 'Var101', 'Var102', 'Var103', 'Var104', 'Var105', 'Var106', 'Var107', 'Var108', 'Var110', 'Var111', 'Var114', 'Var115', 'Var116', 'Var117', 'Var118', 'Var120', 'Var121', 'Var122', 'Var124', 'Var127', 'Var128', 'Var129', 'Var130', 'Var131', 'Var135', 'Var136', 'Var137', 'Var138', 'Var139', 'Var141', 'Var142', 'Var145', 'Var146', 'Var147', 'Var148', 'Var150', 'Var151', 'Var152', 'Var154', 'Var155', 'Var156', 'Var157', 'Var158', 'Var159', 'Var161', 'Var162', 'Var164', 'Var165', 'Var166', 'Var167', 'Var168', 'Var169', 'Var170', 'Var171', 'Var172', 'Var174', 'Var175', 'Var176', 'Var177', 'Var178', 'Var179', 'Var180', 'Var182', 'Var183', 'Var184', 'Var185', 'Var186', 'Var187', 'Var188', 'Var189', 'Var190', 'Var191', 'Var194', 'Var200', 'Var201', 'Var209', 'Var213', 'Var214', 'Var215', 'Var224', 'Var225', 'Var229', 'Var230']\n",
      "New dataset shape after column removal: (10000, 68)\n",
      "New dataset shape after removing rows with more than 30% missing columns: (9080, 68)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "column_threshold = 0.30\n",
    "\n",
    "missing_percent = data.isnull().mean()\n",
    "columns_to_drop = missing_percent[missing_percent > column_threshold].index\n",
    "cleaned_data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Columns removed: {list(columns_to_drop)}\")\n",
    "print(f\"New dataset shape after column removal: {cleaned_data.shape}\")\n",
    "\n",
    "row_threshold = int((1 - 0.30) * cleaned_data.shape[1])\n",
    "cleaned_data = cleaned_data.dropna(thresh=row_threshold)\n",
    "print(f\"New dataset shape after removing rows with more than 30% missing columns: {cleaned_data.shape}\")\n",
    "\n",
    "cleaned_data.to_csv('fully_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1afa0d03-0b59-4ff8-af61-fa0fb1b1f15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature summary exported to feature_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Separate numeric and categorical feature names\n",
    "numeric_features = cleaned_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = cleaned_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "export_feature_summary(cleaned_data, 'feature_summary.csv', unique_threshold = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db724cda-733c-4c97-abe3-6813d2d30940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222148d8-916b-4fa2-abc4-789abbbf463e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
