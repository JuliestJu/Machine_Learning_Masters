{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec290c0-c953-49f0-8d57-d643137b2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from feature_summary import export_feature_summary\n",
    "from round_to_nearest import round_to_nearest_multiple\n",
    "from split_dataset_by_missing_and_type import split_dataset_by_missing_and_type\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1abe2ed-73c5-43c9-83ba-7b49b4b0d8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_proj_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb3adc0-34a9-49b7-9d60-72abe84f2b9f",
   "metadata": {},
   "source": [
    "### Removing Missing Rows and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae704a41-ab37-4d91-8224-ea5cc14996ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 231)\n",
      "Columns removed: ['Var1', 'Var2', 'Var3', 'Var4', 'Var5', 'Var8', 'Var9', 'Var10', 'Var11', 'Var12', 'Var14', 'Var15', 'Var16', 'Var17', 'Var18', 'Var19', 'Var20', 'Var23', 'Var26', 'Var27', 'Var29', 'Var30', 'Var31', 'Var32', 'Var33', 'Var34', 'Var36', 'Var37', 'Var39', 'Var40', 'Var41', 'Var42', 'Var43', 'Var45', 'Var46', 'Var47', 'Var48', 'Var49', 'Var50', 'Var51', 'Var52', 'Var53', 'Var54', 'Var55', 'Var56', 'Var58', 'Var59', 'Var60', 'Var61', 'Var62', 'Var63', 'Var64', 'Var66', 'Var67', 'Var68', 'Var69', 'Var70', 'Var71', 'Var72', 'Var75', 'Var77', 'Var79', 'Var80', 'Var82', 'Var84', 'Var86', 'Var87', 'Var88', 'Var89', 'Var90', 'Var91', 'Var92', 'Var93', 'Var94', 'Var95', 'Var96', 'Var97', 'Var98', 'Var99', 'Var100', 'Var101', 'Var102', 'Var103', 'Var104', 'Var105', 'Var106', 'Var107', 'Var108', 'Var110', 'Var111', 'Var114', 'Var115', 'Var116', 'Var117', 'Var118', 'Var120', 'Var121', 'Var122', 'Var124', 'Var127', 'Var128', 'Var129', 'Var130', 'Var131', 'Var135', 'Var136', 'Var137', 'Var138', 'Var139', 'Var141', 'Var142', 'Var145', 'Var146', 'Var147', 'Var148', 'Var150', 'Var151', 'Var152', 'Var154', 'Var155', 'Var156', 'Var157', 'Var158', 'Var159', 'Var161', 'Var162', 'Var164', 'Var165', 'Var166', 'Var167', 'Var168', 'Var169', 'Var170', 'Var171', 'Var172', 'Var174', 'Var175', 'Var176', 'Var177', 'Var178', 'Var179', 'Var180', 'Var182', 'Var183', 'Var184', 'Var185', 'Var186', 'Var187', 'Var188', 'Var189', 'Var190', 'Var191', 'Var194', 'Var200', 'Var201', 'Var209', 'Var213', 'Var214', 'Var215', 'Var224', 'Var225', 'Var229', 'Var230']\n",
      "New dataset shape after column removal: (10000, 68)\n",
      "New dataset shape after removing rows with more than 30% missing columns: (9080, 68)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "column_threshold = 0.30\n",
    "\n",
    "missing_percent = data.isnull().mean()\n",
    "columns_to_drop = missing_percent[missing_percent > column_threshold].index\n",
    "cleaned_data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Columns removed: {list(columns_to_drop)}\")\n",
    "print(f\"New dataset shape after column removal: {cleaned_data.shape}\")\n",
    "\n",
    "row_threshold = int((1 - 0.30) * cleaned_data.shape[1])\n",
    "cleaned_data = cleaned_data.dropna(thresh=row_threshold)\n",
    "print(f\"New dataset shape after removing rows with more than 30% missing columns: {cleaned_data.shape}\")\n",
    "\n",
    "cleaned_data.to_csv('fully_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17131eb5-0cc7-4216-afa8-9674346b9351",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afa0d03-0b59-4ff8-af61-fa0fb1b1f15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature summary exported to feature_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Separate numeric and categorical feature names\n",
    "numeric_features = cleaned_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = cleaned_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "export_feature_summary(cleaned_data, 'feature_summary.csv', unique_threshold = 40)\n",
    "summary_df = pd.read_csv('feature_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941ac169-ebad-4aec-a2fd-96cbba9d6a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Files saved successfully.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MISSING VALUES\n",
    "features_with_missing_values_count = summary_df[summary_df['Missing Value Count'] > 0].shape[0]\n",
    "print(features_with_missing_values_count)\n",
    "split_dataset_by_missing_and_type(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15cebead-5755-4194-a631-235db51f6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables with no missing values\n",
    "categorical_variables_no_missing = [\n",
    "    'Var196', 'Var207', 'Var226', 'Var211', 'Var198', 'Var199', \n",
    "    'Var202', 'Var204', 'Var212', 'Var216', 'Var220', 'Var222', \n",
    "    'Var227', 'Var193', 'Var228', 'Var195', 'Var210', 'Var221'\n",
    "]\n",
    "\n",
    "# Numerical variables with no missing values\n",
    "numerical_variables_no_missing = [\n",
    "    'y', 'Var181', 'Var173', 'Var35', 'Var143', 'Var132', 'Var78', 'Var44',\n",
    "    'Var163', 'Var160', 'Var153', 'Var134', 'Var133', 'Var123', 'Var22', 'Var85',\n",
    "    'Var83', 'Var76', 'Var73', 'Var57', 'Var38', 'Var28', 'Var25', 'Var113', 'Var112'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a3e57-ec62-49fd-804b-5730386495e4",
   "metadata": {},
   "source": [
    "#### Numerical Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e37c2a-bd5c-4337-9003-f56325298c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical continuous variables with missing values <= 100\n",
    "numerical_continuous_missing_leq_100 = ['Var6', 'Var13', 'Var21', 'Var74', 'Var81', 'Var119', 'Var125', 'Var140']\n",
    "# Perform median imputation for the specified variables\n",
    "for col in numerical_continuous_missing_leq_100:\n",
    "    if col in cleaned_data.columns:\n",
    "        median_value = cleaned_data[col].median()\n",
    "        cleaned_data[col] = cleaned_data[col].fillna(median_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58dc4579-e2e6-4ea5-9c57-91cbe6fd4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical continuous variables with missing values > 100 and <= 1000\n",
    "numerical_continuous_missing_between_100_and_1000 = ['Var24', 'Var109', 'Var149']\n",
    "# Numerical continuous variables with missing values > 1000\n",
    "numerical_continuous_missing_gt_1000 = ['Var126']\n",
    "# Numerical ordinal variables with a common divisor of 7\n",
    "numerical_ordinal_divisor_7_group = ['Var7']\n",
    "# Numerical ordinal variables with a common divisor of 9\n",
    "numerical_ordinal_divisor_9_group = ['Var144', 'Var65']\n",
    "\n",
    "# Create a SimpleImputer object with the median strategy\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Apply the imputation on the selected columns\n",
    "cleaned_data[numerical_continuous_missing_gt_1000] = median_imputer.fit_transform(cleaned_data[numerical_continuous_missing_gt_1000])\n",
    "cleaned_data[numerical_continuous_missing_between_100_and_1000] = median_imputer.fit_transform(cleaned_data[numerical_continuous_missing_between_100_and_1000])\n",
    "cleaned_data[numerical_ordinal_divisor_7_group] = median_imputer.fit_transform(cleaned_data[numerical_ordinal_divisor_7_group])\n",
    "cleaned_data[numerical_ordinal_divisor_9_group] = median_imputer.fit_transform(cleaned_data[numerical_ordinal_divisor_9_group])\n",
    "\n",
    "# Apply rounding to nearest multiple of 7 for Var7\n",
    "cleaned_data[numerical_ordinal_divisor_7_group] = cleaned_data[numerical_ordinal_divisor_7_group].apply(lambda x: round_to_nearest_multiple(x, 7))\n",
    "\n",
    "# Apply rounding to nearest multiple of 9 for Var144 and Var65\n",
    "for var in numerical_ordinal_divisor_9_group:\n",
    "    cleaned_data[var] = cleaned_data[var].apply(lambda x: round_to_nearest_multiple(x, 9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425ad60-f52d-4571-815a-36eaffd553ac",
   "metadata": {},
   "source": [
    "#### Categorical Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4355fa14-de28-45e8-8da1-071d8c4b362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORICAL\n",
    "# Categorical continuous variables\n",
    "categorical_continuous_variables = ['Var192', 'Var197', 'Var217']\n",
    "\n",
    "# Create SimpleImputer object with the most frequent strategy\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "cleaned_data[categorical_continuous_variables] = mode_imputer.fit_transform(cleaned_data[categorical_continuous_variables])\n",
    "\n",
    "# Categorical variables with few unique values and up to 345 missing\n",
    "categorical_variables_few_unique_missing_leq_345 = ['Var203', 'Var205', 'Var218', 'Var208']\n",
    "cleaned_data[categorical_variables_few_unique_missing_leq_345] = mode_imputer.fit_transform(cleaned_data[categorical_variables_few_unique_missing_leq_345])\n",
    "\n",
    "# Categorical variables with many unique values and little missing\n",
    "categorical_variables_many_unique_missing_low = ['Var206']\n",
    "# Apply the imputation\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "cleaned_data[categorical_variables_many_unique_missing_low] = constant_imputer.fit_transform(cleaned_data[categorical_variables_many_unique_missing_low])\n",
    "\n",
    "# Categorical variables with many unique values and many missing\n",
    "categorical_variables_many_unique_missing_high = ['Var219']\n",
    "# Apply the KNN imputation on categorical variables with many unique values\n",
    "cleaned_data[categorical_variables_many_unique_missing_high] = constant_imputer.fit_transform(cleaned_data[categorical_variables_many_unique_missing_high])\n",
    "\n",
    "# Categorical variables with few unique values and many missing\n",
    "categorical_variables_few_unique_missing_high = ['Var223']\n",
    "# Apply most frequent imputation\n",
    "cleaned_data[categorical_variables_few_unique_missing_high] = mode_imputer.fit_transform(cleaned_data[categorical_variables_few_unique_missing_high])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e120c0-f7fd-4d86-ac6f-b5a7c57f41ef",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81b65168-a081-4c5d-8456-5653e6588b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature summary exported to feature_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Files saved successfully.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data = cleaned_data\n",
    "imputed_data.to_csv('fully_imputed_data.csv', index=False)\n",
    "export_feature_summary(cleaned_data, 'feature_summary.csv', unique_threshold = 40)\n",
    "summary_df = pd.read_csv('feature_summary.csv')\n",
    "split_dataset_by_missing_and_type(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdc5e234-f2b3-48ff-91e8-7e474fa5d277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var208</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var218</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var208  Var218  Var218\n",
       "0       0       1       1\n",
       "1       0       0       0\n",
       "2       0       1       1\n",
       "3       0       1       1\n",
       "4       0       1       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_features_names = ['Var208', 'Var218', 'Var218']\n",
    "label_encoders = {}\n",
    "for feature in binary_features_names:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    imputed_data[feature] = label_encoders[feature].fit_transform(imputed_data[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed95d70-6884-46f7-9b5c-70ca074bcff2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var38</th>\n",
       "      <th>...</th>\n",
       "      <th>Var207_5iay</th>\n",
       "      <th>Var207_6C53VA1kCv</th>\n",
       "      <th>Var207_7M47J5GA0pTYIFxg5uy</th>\n",
       "      <th>Var207_DHn_WUyBhW_whjA88g9bvA64_</th>\n",
       "      <th>Var207_EBKcR3s6B22tD6gC36gm6S</th>\n",
       "      <th>Var207_GjJ35utlTa_GNSvxxpb9ju</th>\n",
       "      <th>Var207_Kxdu</th>\n",
       "      <th>Var207_NKv3VA1BpP</th>\n",
       "      <th>Var207_me75fM6ugJ</th>\n",
       "      <th>Var207_wXfldy7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>812.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>286.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4850466.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2688.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8820.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132072.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>294.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3223524.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>644.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2135430.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3110400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Var6  Var7   Var13  Var21  Var22  Var24  Var25   Var28  Var35      Var38  \\\n",
       "0   812.0  14.0  1252.0  156.0  195.0    0.0   40.0  286.96    0.0  4850466.0   \n",
       "1  2688.0   7.0  8820.0  364.0  455.0    4.0  288.0  200.00    0.0   132072.0   \n",
       "2  1015.0  14.0  1784.0  136.0  170.0    2.0   40.0  294.48    0.0  3223524.0   \n",
       "3   168.0   0.0     0.0   24.0   30.0    0.0    0.0  644.24    0.0  2135430.0   \n",
       "4    14.0   0.0     0.0   36.0   45.0    0.0    0.0  239.84    0.0  3110400.0   \n",
       "\n",
       "   ...  Var207_5iay  Var207_6C53VA1kCv  Var207_7M47J5GA0pTYIFxg5uy  \\\n",
       "0  ...        False              False                        True   \n",
       "1  ...        False              False                       False   \n",
       "2  ...        False              False                        True   \n",
       "3  ...        False              False                       False   \n",
       "4  ...        False              False                       False   \n",
       "\n",
       "   Var207_DHn_WUyBhW_whjA88g9bvA64_  Var207_EBKcR3s6B22tD6gC36gm6S  \\\n",
       "0                             False                          False   \n",
       "1                             False                          False   \n",
       "2                             False                          False   \n",
       "3                             False                          False   \n",
       "4                             False                          False   \n",
       "\n",
       "   Var207_GjJ35utlTa_GNSvxxpb9ju  Var207_Kxdu  Var207_NKv3VA1BpP  \\\n",
       "0                          False        False              False   \n",
       "1                          False        False              False   \n",
       "2                          False        False              False   \n",
       "3                          False        False              False   \n",
       "4                          False        False              False   \n",
       "\n",
       "   Var207_me75fM6ugJ  Var207_wXfldy7  \n",
       "0              False           False  \n",
       "1               True           False  \n",
       "2              False           False  \n",
       "3               True           False  \n",
       "4               True           False  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding_names = ['Var196', 'Var205', 'Var223', 'Var203', 'Var210', 'Var221', 'Var227', 'Var207']\n",
    "# Apply one-hot encoding using pd.get_dummies\n",
    "imputed_data_one_hot_encoded = pd.get_dummies(imputed_data, columns=one_hot_encoding_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca157ec6-fbe3-477b-bfaf-2379b233ab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Var195    Var219    Var206    Var226    Var228    Var193    Var212  \\\n",
      "0  0.95793  0.013106  0.010683  0.050771  0.062445  0.014978  0.007819   \n",
      "1  0.95793  0.020595  0.019934  0.076762  0.103965  0.173348  0.153744   \n",
      "2  0.95793  0.821476  0.065529  0.050771  0.038767  0.672026  0.002093   \n",
      "3  0.95793  0.821476  0.129736  0.155837  0.595485  0.672026  0.526432   \n",
      "4  0.95793  0.821476  0.383590  0.076762  0.595485  0.672026  0.526432   \n",
      "\n",
      "     Var204  \n",
      "0  0.020154  \n",
      "1  0.019383  \n",
      "2  0.020154  \n",
      "3  0.022026  \n",
      "4  0.019383  \n"
     ]
    }
   ],
   "source": [
    "freequency_encoding_names = ['Var195', 'Var219', 'Var206', 'Var226', 'Var228', 'Var193', 'Var212', 'Var204']\n",
    "# Apply frequency encoding to each feature\n",
    "for feature in freequency_encoding_names:\n",
    "    frequency_map = imputed_data[feature].value_counts() / len(imputed_data)\n",
    "    imputed_data[feature] = imputed_data[feature].map(frequency_map)\n",
    "\n",
    "# Display the first few rows of the dataset after frequency encoding\n",
    "print(imputed_data[freequency_encoding_names].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55cd675a-3e7c-43a3-a6a5-b6a87bbc5814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Var197    Var192\n",
      "0  0.098361  0.140000\n",
      "1  0.126829  0.046512\n",
      "2  0.134375  0.000000\n",
      "3  0.134375  0.155556\n",
      "4  0.117647  0.051282\n"
     ]
    }
   ],
   "source": [
    "target_encoding_names = ['Var197', 'Var192']\n",
    "# Apply target encoding\n",
    "for feature in target_encoding_names:\n",
    "    # Create a mapping from category to mean target value\n",
    "    target_mean = imputed_data.groupby(feature)['y'].mean()\n",
    "    imputed_data[feature] = imputed_data[feature].map(target_mean)\n",
    "\n",
    "# Display the first few rows of the dataset after target encoding\n",
    "print(imputed_data[target_encoding_names].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d105c56a-4f72-46da-93b2-32498786413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Var220    Var198    Var216    Var199    Var222\n",
      "0  0.002412  0.002412  0.110866  0.209440  0.002412\n",
      "1  0.073911  0.073911  0.102338  0.243477  0.073911\n",
      "2  0.022207  0.022207  0.110866  0.093412  0.022207\n",
      "3  0.195906  0.195906  0.222026  0.253828  0.195906\n",
      "4  0.083150  0.083150  0.270281  0.224574  0.083150\n"
     ]
    }
   ],
   "source": [
    "smoothning_target_encoding_names = ['Var220', 'Var198', 'Var216', 'Var199', 'Var222']\n",
    "# Assuming your target variable is called 'y' (replace 'y' with the actual target column name)\n",
    "global_mean = imputed_data['y'].mean()\n",
    "\n",
    "# Define a smoothing factor (you can adjust this value)\n",
    "alpha = 10\n",
    "\n",
    "# Apply smoothing target encoding\n",
    "for feature in smoothning_target_encoding_names:\n",
    "    # Calculate category mean and the count of occurrences\n",
    "    category_stats = imputed_data.groupby(feature)['y'].agg(['mean', 'count'])\n",
    "    \n",
    "    # Apply the smoothing formula\n",
    "    smooth = (category_stats['count'] * category_stats['mean'] + alpha * global_mean) / (category_stats['count'] + alpha)\n",
    "    \n",
    "    # Map the smoothed values back to the original feature\n",
    "    imputed_data[feature] = imputed_data[feature].map(smooth)\n",
    "\n",
    "# Display the first few rows of the dataset after smoothing target encoding\n",
    "print(imputed_data[smoothning_target_encoding_names].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c406f11d-da58-4082-93ff-6444748a271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Var202_hashed  Var217_hashed\n",
      "0             89             95\n",
      "1             20             71\n",
      "2             28             77\n",
      "3              6             35\n",
      "4             76             68\n"
     ]
    }
   ],
   "source": [
    "hashing_encoding_names = ['Var202', 'Var217']\n",
    "import hashlib\n",
    "\n",
    "# Define the number of buckets for the hash function (adjust this value as needed)\n",
    "n_buckets = 100\n",
    "\n",
    "# Function to apply hashing encoding\n",
    "def hash_encode(value, n_buckets):\n",
    "    return int(hashlib.md5(str(value).encode()).hexdigest(), 16) % n_buckets\n",
    "\n",
    "# Apply hashing encoding to each feature\n",
    "for feature in hashing_encoding_names:\n",
    "    imputed_data[feature + '_hashed'] = imputed_data[feature].apply(lambda x: hash_encode(x, n_buckets))\n",
    "\n",
    "# Display the first few rows of the dataset after hashing encoding\n",
    "print(imputed_data[[feature + '_hashed' for feature in hashing_encoding_names]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603b77e-8535-4677-91fa-6b1ec8147149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
